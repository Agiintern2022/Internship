{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1722101709/Internship/blob/feedback_protocol_with_16-bit-data/feedback_protocol_with_16_bit_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "2uWVQ8od1Tgc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "from collections import deque\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = 16 # no of bits"
      ],
      "metadata": {
        "id": "odQQszgwFLoB"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ELPLlfjp-zji"
      },
      "outputs": [],
      "source": [
        "class OUNoise(object): # noise class\n",
        "    def __init__(self, action_space, mu=0.0, theta=0.15, max_sigma=0.3, min_sigma=0.3, decay_period=100000):\n",
        "        self.mu           = mu\n",
        "        self.theta        = theta\n",
        "        self.sigma        = max_sigma\n",
        "        self.max_sigma    = max_sigma\n",
        "        self.min_sigma    = min_sigma\n",
        "        self.decay_period = decay_period\n",
        "        self.action_dim   = action_space.shape[0]\n",
        "        self.low          = action_space.low\n",
        "        self.high         = action_space.high\n",
        "        self.reset()\n",
        "        \n",
        "    def reset(self): # resetting the state\n",
        "        self.state = np.ones(self.action_dim) * self.mu\n",
        "        \n",
        "    def evolve_state(self): # exploring the next state\n",
        "        x  = self.state\n",
        "        dx = self.theta * (self.mu - x) + self.sigma * np.random.randn(self.action_dim)\n",
        "        self.state = x + dx\n",
        "        return self.state\n",
        "    \n",
        "    def get_action(self, action, t=0): # get action for the current state\n",
        "        ou_state = self.evolve_state()\n",
        "        self.sigma = self.max_sigma - (self.max_sigma - self.min_sigma) * min(1.0, t / self.decay_period)\n",
        "        return np.clip(action + ou_state, self.low, self.high)\n",
        "\n",
        "\n",
        "        \n",
        "# memory class to store the experiences\n",
        "class Memory:\n",
        "    def __init__(self, max_size): # initializing memory with max_size\n",
        "        self.max_size = max_size\n",
        "        self.buffer = deque(maxlen=max_size)\n",
        "    \n",
        "    def push(self, state, action, reward, next_state, done): # push method to add experience into the memory\n",
        "        experience = (state, action, np.array([reward]), next_state, done)\n",
        "        self.buffer.append(experience)\n",
        "\n",
        "    def sample(self, batch_size): # seperating the elements in the experience into  seperate lists\n",
        "        state_batch = [] # states\n",
        "        action_batch = [] # actions\n",
        "        reward_batch = [] # rewards\n",
        "        next_state_batch = [] # next state\n",
        "        done_batch = [] # is_done\n",
        "\n",
        "        batch = random.sample(self.buffer, batch_size)\n",
        "\n",
        "        for experience in batch:\n",
        "            state, action, reward, next_state, done = experience\n",
        "            state_batch.append(state)\n",
        "            action_batch.append(action)\n",
        "            reward_batch.append(reward)\n",
        "            next_state_batch.append(next_state)\n",
        "            done_batch.append(done)\n",
        "        \n",
        "        return state_batch, action_batch, reward_batch, next_state_batch, done_batch\n",
        "\n",
        "    def __len__(self): # to get the size of the memory filled with experiences\n",
        "        return len(self.buffer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "8_HsRP3x-2w9"
      },
      "outputs": [],
      "source": [
        "# importing necessary modules\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "import torch.autograd\n",
        "from torch.autograd import Variable\n",
        "\n",
        "class Critic(nn.Module): # critic class to implement the critic network \n",
        "    \n",
        "    def __init__(self, input_size, hidden_size, output_size): # initializing the critic network\n",
        "        super(Critic, self).__init__()\n",
        "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "        self.linear2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.linear3 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, state, action): # forward propogation i.e., input to the input layer => output from the output layer\n",
        "\n",
        "        x = torch.cat([state, action], 1)\n",
        "        x = F.relu(self.linear1(x))\n",
        "        x = F.relu(self.linear2(x))\n",
        "        x = self.linear3(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class Actor(nn.Module): # Actor class to implement the Actor Network\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, output_size, learning_rate = 3e-4): # initializing the Actor network\n",
        "        super(Actor, self).__init__()\n",
        "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "        self.linear2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.linear3 = nn.Linear(hidden_size, output_size)\n",
        "        \n",
        "    def forward(self, state): # forward propogation in Actor network with input\n",
        "\n",
        "        x = F.relu(self.linear1(state))\n",
        "        x = F.relu(self.linear2(x))\n",
        "        x = torch.tanh(self.linear3(x))\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "qLB_UGUS-7OI"
      },
      "outputs": [],
      "source": [
        "# importing necessary modules \n",
        "import torch\n",
        "import torch.autograd\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class DDPGagent: # agent class(Deep Deterministic Policy Gradient)\n",
        "\n",
        "    # initilaizations\n",
        "    def __init__(self, env, hidden_size=256, actor_learning_rate=1e-4, critic_learning_rate=1e-3, gamma=0.99, tau=1e-2, max_memory_size=50000):\n",
        "        # Parameters\n",
        "        self.num_states = env.observation_space.shape[0] # number of states\n",
        "        self.num_actions = env.action_space.shape[0] # no of actions\n",
        "        self.gamma = gamma\n",
        "        self.tau = tau\n",
        "\n",
        "        # Networks\n",
        "        self.actor = Actor(self.num_states, hidden_size, self.num_actions) # actor network\n",
        "        self.actor_target = Actor(self.num_states, hidden_size, self.num_actions) # actor target network\n",
        "        self.critic = Critic(self.num_states + self.num_actions, hidden_size, self.num_actions) # critic network\n",
        "        self.critic_target = Critic(self.num_states + self.num_actions, hidden_size, self.num_actions) # critic target network\n",
        "\n",
        "        for target_param, param in zip(self.actor_target.parameters(), self.actor.parameters()):\n",
        "            target_param.data.copy_(param.data)\n",
        "\n",
        "        for target_param, param in zip(self.critic_target.parameters(), self.critic.parameters()):\n",
        "            target_param.data.copy_(param.data)\n",
        "        \n",
        "        # Training\n",
        "        self.memory = Memory(max_memory_size) # initialize the memory  \n",
        "        self.critic_criterion  = nn.MSELoss() # loss function\n",
        "        self.actor_optimizer  = optim.Adam(self.actor.parameters(), lr=actor_learning_rate) # optimizers for actor network\n",
        "        self.critic_optimizer = optim.Adam(self.critic.parameters(), lr=critic_learning_rate) # optimizers for critic network\n",
        "    \n",
        "    def get_action(self, state): # to get the action for the state by passing state as input to the actor network\n",
        "        state = Variable(torch.from_numpy(state).float().unsqueeze(0))\n",
        "        action = self.actor.forward(state)\n",
        "        action = action.detach().numpy()[0,0]\n",
        "        return action\n",
        "    \n",
        "    def update(self, batch_size): # updating the sampling after batch_size iterations\n",
        "        states, actions, rewards, next_states, _ = self.memory.sample(batch_size)\n",
        "        states = torch.FloatTensor(states)\n",
        "        actions = torch.FloatTensor(actions)\n",
        "        rewards = torch.FloatTensor(rewards)\n",
        "        next_states = torch.FloatTensor(next_states)\n",
        "    \n",
        "        # Critic loss        \n",
        "        Qvals = self.critic.forward(states, actions)\n",
        "        next_actions = self.actor_target.forward(next_states)\n",
        "        next_Q = self.critic_target.forward(next_states, next_actions.detach())\n",
        "        Qprime = rewards + self.gamma * next_Q\n",
        "        critic_loss = self.critic_criterion(Qvals, Qprime)\n",
        "\n",
        "        # Actor loss\n",
        "        policy_loss = -self.critic.forward(states, self.actor.forward(states)).mean()\n",
        "        \n",
        "        # update networks\n",
        "        self.actor_optimizer.zero_grad() # actor network\n",
        "        policy_loss.backward()\n",
        "        self.actor_optimizer.step()\n",
        "\n",
        "        self.critic_optimizer.zero_grad() # critic network\n",
        "        critic_loss.backward() \n",
        "        self.critic_optimizer.step()\n",
        "\n",
        "        # update target networks \n",
        "        for target_param, param in zip(self.actor_target.parameters(), self.actor.parameters()):\n",
        "            target_param.data.copy_(param.data * self.tau + target_param.data * (1.0 - self.tau))\n",
        "       \n",
        "        for target_param, param in zip(self.critic_target.parameters(), self.critic.parameters()):\n",
        "            target_param.data.copy_(param.data * self.tau + target_param.data * (1.0 - self.tau))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "zE84Q12h_D5D"
      },
      "outputs": [],
      "source": [
        "# importing modules\n",
        "from gym import Env\n",
        "from gym.spaces import Discrete, Box\n",
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "import random\n",
        "from sklearn.preprocessing import StandardScaler, normalize\n",
        "from sklearn.decomposition import PCA\n",
        "# Environment\n",
        "class Environment(Env):\n",
        "\n",
        "    def __init__(self): # initializing environment\n",
        "        self.action_space = Box(low = np.array([-1]), high = np.array([1]), dtype=float)\n",
        "        self.observation_space = Box(low = np.array([-1]), high = np.array([1]), dtype=float)\n",
        "        self.state = np.round(np.random.random(1), decimals=2)\n",
        "        self.n = 2**n\n",
        "        self.data = self.get_data(self.n)\n",
        "        self.iter = 0\n",
        "    def step(self, action): # taking actions on environment\n",
        "\n",
        "        reward = abs(action)\n",
        "        done, next_state = True if self.iter  == self.n-2 else  False, np.array([self.data[self.iter+1]])\n",
        "        self.state = next_state\n",
        "        self.iter += 1\n",
        "        return self.state,reward,done,{}\n",
        "    def get_data(self,n):\n",
        "        x = []\n",
        "        for i in range(n):\n",
        "            pattern = '{0:0'+str(n)+'b}'\n",
        "            y = pattern.format(random.randint(1,n))\n",
        "            x.append([ord(j)-ord('0') for j in y])\n",
        "        x = pd.DataFrame(x)\n",
        "        c = len(x.columns)\n",
        "        if c == 17:del x[n]\n",
        "        x_scaler = StandardScaler().fit_transform(x) # Scaling\n",
        "        x_normalize = pd.DataFrame(normalize(x_scaler)) # normalizing\n",
        "        \n",
        "        x_pca = pd.DataFrame(PCA(n_components=1).fit_transform(x_normalize)) # applying PCA and storing the result in dataframe\n",
        "\n",
        "        return list(x_pca[0])\n",
        "    def reset(self): # reset the environment\n",
        "        self.__init__()\n",
        "        return self.state\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKmcyP_4QPwZ",
        "outputId": "09d4257c-c8ed-4b88-a841-d4ef505ca141"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "episode: 1, reward: 32821.24, average _reward: 32821.23881686684 \n",
            "\n",
            "episode: 2, reward: 32669.24, average _reward: 32745.237521462055 \n",
            "\n",
            "episode: 3, reward: 32796.85, average _reward: 32762.440797805553 \n",
            "\n",
            "episode: 4, reward: 32930.75, average _reward: 32804.51708472024 \n",
            "\n",
            "episode: 5, reward: 32602.43, average _reward: 32764.09914727183 \n",
            "\n",
            "episode: 6, reward: 32752.11, average _reward: 32762.101331942522 \n",
            "\n",
            "episode: 7, reward: 32685.09, average _reward: 32751.099568689246 \n",
            "\n",
            "episode: 8, reward: 32765.6, average _reward: 32752.912140001165 \n",
            "\n",
            "episode: 9, reward: 32798.17, average _reward: 32757.94074683526 \n",
            "\n",
            "episode: 10, reward: 32578.55, average _reward: 32740.002128137225 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "#importing modules\n",
        "import sys\n",
        "import gym\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "env = Environment() # creating environment\n",
        "\n",
        "agent = DDPGagent(env) # agent\n",
        "noise = OUNoise(env.action_space) # noise class object\n",
        "batch_size = 2 \n",
        "rewards = []\n",
        "avg_rewards = []\n",
        "episodes = 10 # no of episodes\n",
        "steps = 2**n-1 # no of steps in an episode\n",
        "for episode in range(episodes):\n",
        "    state = env.reset()\n",
        "    noise.reset()\n",
        "    episode_reward = 0\n",
        "    for step in range(steps):\n",
        "        action = random.uniform(-1,1) # random action\n",
        "        new_state, reward, done, _ = env.step(action) # apply action on the environment\n",
        "        \n",
        "        state = new_state\n",
        "        episode_reward += reward\n",
        "        if done: # if environment was explored fully then, stop\n",
        "            break\n",
        " \n",
        "    rewards.append(episode_reward)\n",
        "    avg_rewards.append(np.mean(rewards[-10:]))\n",
        "    # print total reward for the episode and average_reward per episode\n",
        "    print(\"episode: {}, reward: {}, average _reward: {} \\n\".format(episode+1, np.round(episode_reward, decimals=2), np.mean(rewards[-10:])))\n",
        "without_feedback_rewards = rewards\n",
        "without_feedback_avg_rewards = avg_rewards\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_0vXX_e_I2A",
        "outputId": "86e570e8-bbf5-4134-f977-0ecb58fe45ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "episode: 1, reward: [51735.49], average _reward: 51735.491646213675 \n",
            "\n",
            "episode: 2, reward: [51675.93], average _reward: 51705.71092022459 \n",
            "\n",
            "episode: 3, reward: [51752.38], average _reward: 51721.26688520432 \n",
            "\n",
            "episode: 4, reward: [51693.35], average _reward: 51714.28884552134 \n",
            "\n",
            "episode: 5, reward: [51675.45], average _reward: 51706.521204447796 \n",
            "\n",
            "episode: 6, reward: [51442.64], average _reward: 51662.54090822672 \n",
            "\n",
            "episode: 7, reward: [51742.37], average _reward: 51673.94471259007 \n",
            "\n",
            "episode: 8, reward: [52111.42], average _reward: 51728.62906650451 \n",
            "\n",
            "episode: 9, reward: [51266.18], average _reward: 51677.24577462014 \n",
            "\n",
            "episode: 10, reward: [51448.11], average _reward: 51654.331922859754 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "#importing modules\n",
        "import sys\n",
        "import gym\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "env = Environment() # creating environment\n",
        "\n",
        "agent = DDPGagent(env) # agent\n",
        "noise = OUNoise(env.action_space) # noise class object\n",
        "batch_size = 2 \n",
        "rewards = []\n",
        "avg_rewards = []\n",
        "episodes = 10 # no of episodes\n",
        "steps = 2**n-1 # no of steps in an episode\n",
        "for episode in range(episodes):\n",
        "    state = env.reset()\n",
        "    noise.reset()\n",
        "    episode_reward = 0\n",
        "    for step in range(steps):\n",
        "        action = agent.get_action(state) # get action from Agent\n",
        "        action = noise.get_action(action, step) # add noise to the action\n",
        "        new_state, reward, done, _ = env.step(action) # apply action on the environment\n",
        "        agent.memory.push(state, action, reward, new_state, done) # store the experience in the memory\n",
        "        \n",
        "        if len(agent.memory) > batch_size: # update the sampling after batch_size iterations\n",
        "            agent.update(batch_size)\n",
        "        \n",
        "        state = new_state\n",
        "        episode_reward += reward\n",
        "        if done: # if environment was explored fully then, stop\n",
        "            break\n",
        " \n",
        "    rewards.append(episode_reward)\n",
        "    avg_rewards.append(np.mean(rewards[-10:]))\n",
        "    # print total reward for the episode and average_reward per episode\n",
        "    print(\"episode: {}, reward: {}, average_reward: {} \\n\".format(episode+1, np.round(episode_reward, decimals=2), np.mean(rewards[-10:])))\n",
        "with_feedback_rewards = rewards\n",
        "with_feedback_avg_rewards = avg_rewards"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "without_feedback_avg_rewards"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gi4wX8qvGMhi",
        "outputId": "dd455b29-132d-43a5-88bd-3a3facee2994"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[32821.23881686684,\n",
              " 32745.237521462055,\n",
              " 32762.440797805553,\n",
              " 32804.51708472024,\n",
              " 32764.09914727183,\n",
              " 32762.101331942522,\n",
              " 32751.099568689246,\n",
              " 32752.912140001165,\n",
              " 32757.94074683526,\n",
              " 32740.002128137225]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with_feedback_avg_rewards"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5NQvZUXGQUH",
        "outputId": "75c52a54-d65d-46ae-c0d3-4f9eebd6eace"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[51735.491646213675,\n",
              " 51705.71092022459,\n",
              " 51721.26688520432,\n",
              " 51714.28884552134,\n",
              " 51706.521204447796,\n",
              " 51662.54090822672,\n",
              " 51673.94471259007,\n",
              " 51728.62906650451,\n",
              " 51677.24577462014,\n",
              " 51654.331922859754]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "GtnmJLu0_Jwz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "d67d3979-1f8a-46c1-f0c1-a02735c6bffa"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import matplotlib as mpl\n",
        "plt.plot(with_feedback_avg_rewards,'g',linewidth=3, marker='s')\n",
        "plt.plot(without_feedback_avg_rewards,'r',linewidth=1.5, marker = 'o')\n",
        "plt.plot()\n",
        "plt.legend([\"with feedback\", \"without feedback\"], loc =\"center\")\n",
        "plt.xlabel('Episodes')\n",
        "plt.ylabel('Average Reward')\n",
        "plt.title('average rewards w.r.t episodes')\n",
        "plt.style.use('dark_background')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "feedback_protocol_with_16-bit_data.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNKBgbe3p+h0l6aDuIsWKAr",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}